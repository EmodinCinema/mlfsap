{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfda55d5-0cd3-4ba9-a287-1788ee396dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import yaml\n",
    "from copy import copy\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c06b6a5e-8b70-4806-bff0-8e4e3682cc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./edu_train.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "CLASSES = config['names']\n",
    "print(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da8ca21c-3e2c-4dc2-abcc-bc72e6c9dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = './dataset/image/train/'\n",
    "IMG_PATHS = [os.path.join(img_dir, img_name)\n",
    "             for img_name in os.listdir(img_dir)\n",
    "             if os.path.isfile(os.path.join(img_dir, img_name))]\n",
    "print(IMG_PATHS[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44ec2f27-a62f-4baf-844d-fbf6bb800635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(img_path):\n",
    "    image = np.array(Image.open(img_path))\n",
    "\n",
    "    labels_path = img_path.replace('image', 'labels').replace(img_path.split('.')[-1], 'txt')\n",
    "    class_ids = []\n",
    "    boxes = []\n",
    "    with open(labels_path) as file:\n",
    "        for line in file:\n",
    "            line = line.rstrip()\n",
    "            items = line.split(' ')\n",
    "            class_ids.append(int(items[0]))\n",
    "            \n",
    "            box = [float(point) for point in items[1:]]\n",
    "            box = [point if point < 1 else 0.99\n",
    "                   for point in box]\n",
    "            boxes.append(box)\n",
    "    return image, class_ids, boxes\n",
    "\n",
    "\n",
    "def parse_boxes(img_shape, boxes):\n",
    "    y_size, x_size = img_shape[:2]\n",
    "    for box in boxes:\n",
    "        x_center = box[0] * x_size\n",
    "        y_center = box[1] * y_size\n",
    "        width = box[2] * x_size \n",
    "        height = box[3] * y_size \n",
    "\n",
    "        x1y1 = (int(x_center-(width/2)), int(y_center-(height/2)))\n",
    "        x2y2 = (int(x_center+(width/2)), int(y_center+(height/2)))\n",
    "        \n",
    "        yield [x1y1, x2y2]\n",
    "        \n",
    "        \n",
    "def put_box(img, class_ids, parsed_boxes, pred_confs):\n",
    "    img = copy(img)\n",
    "    for class_id, box, conf in zip(class_ids, parsed_boxes, pred_confs):\n",
    "        x1y1, x2y2 = box\n",
    "        img = cv2.rectangle(img, x1y1, x2y2, (0, 255, 255), 2)\n",
    "        img = cv2.putText(img, f'{CLASSES[class_id]} {conf}',\n",
    "                          x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL, 1,\n",
    "                          (255, 0, 255), 2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def parse_pred(predicts):\n",
    "    pred_classes = [int(cur_pred) for cur_pred in predicts['classes'] if cur_pred or cur_pred==0]\n",
    "    pred_confs= [round(cur_pred, 3) for cur_pred in predicts['conf'] if pred_classes]\n",
    "\n",
    "    pred_boxes = [[(int(cur_pred[0]), int(cur_pred[1])), (int(cur_pred[2]), int(cur_pred[3]))] for cur_pred in predicts['boxes'] if pred_classes]\n",
    "    return pred_classes, pred_boxes, pred_confs\n",
    "\n",
    "def get_pred(model, img):\n",
    "    results = model.predict(source=img, device=1, verbose=True)\n",
    "    for result in results:\n",
    "        pred_class = result.boxes.cls.cpu().numpy().squeeze().tolist()\n",
    "        pred_box = result.boxes.xyxy.cpu().numpy().squeeze().tolist()\n",
    "        conf = result.boxes.conf.cpu().numpy().squeeze().tolist()\n",
    "        \n",
    "        if type(pred_class) != list:\n",
    "            pred_class = [pred_class]\n",
    "        if type(conf) != list:\n",
    "            conf = [conf]\n",
    "        if not pred_box:\n",
    "            pred_box = [pred_box]\n",
    "        elif type(pred_box[0]) != list:\n",
    "            pred_box = [pred_box]\n",
    "        \n",
    "        yield {'classes': pred_class, 'boxes': pred_box, 'conf': conf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa15e41f-c76d-478a-b48a-0a43abc10670",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = YOLO(\"path/to/weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "790118db-c844-4916-b0d3-e425a891f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_ITER = iter(IMG_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fbd8af6a-7576-40f1-84f8-bd17befabbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(images):\n",
    "    fig = px.imshow(np.array(images), facet_col=0, facet_col_wrap=2, height = 1200)\n",
    "    annotations = ['True', 'Predict', 'GrabCut_by_Pred', 'GrabCut_by_Full']\n",
    "    item_map = {f'{i}': key for i, key in enumerate(annotations)}\n",
    "    fig.for_each_annotation(lambda a: a.update(text=item_map[a.text.split(\"=\")[1]]))\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "    \n",
    "def grab_cut(img, boxes):\n",
    "    bgdModel = np.zeros((1, 65), np.float64)\n",
    "    fgdModel = np.zeros((1, 65), np.float64)\n",
    "    \n",
    "    total_mask = np.zeros(img.shape[:2], np.uint8)\n",
    "    if boxes is None:\n",
    "        y_shape, x_shape = img.shape[:2]\n",
    "        boxes = [[(0,0),(x_shape-1,y_shape-1)]]\n",
    "    \n",
    "    for box in boxes:\n",
    "        x1y1, x2y2 = box\n",
    "        rect = (x1y1[0], x1y1[1], x2y2[0] - x1y1[0], x2y2[1] - x1y1[1])\n",
    "\n",
    "        mask = np.zeros(img.shape[:2], np.uint8)\n",
    "        cv2.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
    "        \n",
    "        mask = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')        \n",
    "        total_mask[mask==1] = 1\n",
    "        \n",
    "    img = img * total_mask[:, :, np.newaxis]\n",
    "    return img\n",
    "    \n",
    "def plot_result():\n",
    "    img_path = next(IMG_ITER)\n",
    "    \n",
    "    image, true_class_ids, true_boxes = loader(img_path)\n",
    "    true_boxes = [*parse_boxes(image.shape, true_boxes)]\n",
    "    \n",
    "    pred_classes, pred_boxes, pred_confs = parse_pred(*get_pred(MODEL, image))\n",
    "    \n",
    "    true_img = put_box(image, true_class_ids, true_boxes, ['' for conf in pred_confs])\n",
    "    pred_img = put_box(image, pred_classes, pred_boxes, pred_confs)\n",
    "    grab_cut_img = grab_cut(image, pred_boxes)\n",
    "    grab_cut_true_img = grab_cut(image, boxes=None)\n",
    "\n",
    "    show_plot([true_img, pred_img, grab_cut_img, grab_cut_true_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3632561-1115-4ddf-abfd-e820bc47a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlfsap2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
